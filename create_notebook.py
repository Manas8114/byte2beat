
import json
import os

notebook_structure = {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepMind-Inspired Cardiac Risk Assessment\n",
    "## Hack4Health Reproducible Submission\n",
    "\n",
    "**Team Byte2Beat**\n",
    "\n",
    "This notebook reproduces the training, evaluation, and interpretability pipeline of our 'Clinician's Trust Cockpit'.\n",
    "\n",
    "### Instructions\n",
    "1. Upload `heart_processed.csv` and `cardio_base.csv` to the file browser.\n",
    "2. Run all cells to train the Hybrid Model (XGBoost + TabPFN + Uncertainty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install Dependencies\n",
    "!pip install xgboost tabpfn torch joblib plotly scikit-learn pandas numpy seaborn huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Utils: Data Processing (src/utils_data.py)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_concept_map():\n",
    "    return {\n",
    "        \"Demographics\": [\"Age\", \"Sex_M\", \"Sex_F\", \"Height\", \"Weight\"],\n",
    "        \"Vitals\": [\"RestingBP\", \"Cholesterol\", \"FastingBS\", \"MaxHR\", \"Glucose\"],\n",
    "        \"Lifestyle\": [\"Smoke\", \"Alcohol\", \"Active\"],\n",
    "        \"Clinical\": [\n",
    "            \"Oldpeak\", \n",
    "            \"ChestPainType_ATA\", \"ChestPainType_NAP\", \"ChestPainType_TA\", \"ChestPainType_ASY\", \n",
    "            \"RestingECG_Normal\", \"RestingECG_ST\", \"RestingECG_LVH\",\n",
    "            \"ExerciseAngina_Y\", \n",
    "            \"ST_Slope_Flat\", \"ST_Slope_Up\", \"ST_Slope_Down\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def load_cardio_base(filepath):\n",
    "    df = pd.read_csv(filepath, sep=';')\n",
    "    df['Age'] = (df['age'] / 365.25).astype(int)\n",
    "    df['Sex_M'] = (df['gender'] == 2).astype(int)\n",
    "    df = df.rename(columns={\n",
    "        'ap_hi': 'RestingBP',\n",
    "        'gluc': 'Glucose',\n",
    "        'smoke': 'Smoke',\n",
    "        'alco': 'Alcohol',\n",
    "        'active': 'Active',\n",
    "        'cardio': 'HeartDisease',\n",
    "        'height': 'Height',\n",
    "    })\n",
    "    # Normalized Cholesterol Mapping\n",
    "    df['Cholesterol'] = df['cholesterol'].map({1: 180, 2: 225, 3: 260})\n",
    "    df = df.drop(columns=['id', 'age', 'gender', 'ap_lo', 'cholesterol'])\n",
    "    return df\n",
    "\n",
    "def load_heart_processed(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'bool' or df[col].astype(str).isin(['True', 'False']).any():\n",
    "             df[col] = df[col].map({'True': 1, True: 1, 'False': 0, False: 0})\n",
    "    return df\n",
    "\n",
    "def load_and_preprocess_data(processed_path, base_path=None):\n",
    "    df_proc = load_heart_processed(processed_path)\n",
    "    if base_path:\n",
    "        try:\n",
    "            df_base = load_cardio_base(base_path)\n",
    "            print(f\"Merging: {len(df_proc)} (Proc) + {len(df_base)} (Base)\")\n",
    "            df_final = pd.concat([df_proc, df_base], axis=0, ignore_index=True)\n",
    "            df_final = df_final.fillna(-1)\n",
    "        except Exception as e:\n",
    "            print(f\"Merge failed: {e}\")\n",
    "            df_final = df_proc\n",
    "    else:\n",
    "        df_final = df_proc\n",
    "    \n",
    "    if 'HeartDisease' not in df_final.columns:\n",
    "        raise ValueError(\"Target 'HeartDisease' missing.\")\n",
    "    y = df_final['HeartDisease']\n",
    "    X = df_final.drop(columns=['HeartDisease'])\n",
    "    return X, y, get_concept_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Utils: Model Definitions (src/utils_model.py)\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "class MCDropoutNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UncertaintyModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, epochs=50, lr=0.01):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.model = None\n",
    "    def fit(self, X, y):\n",
    "        X_arr = X.values if hasattr(X, 'values') else X\n",
    "        y_arr = y.values if hasattr(y, 'values') else y\n",
    "        X_tensor = torch.FloatTensor(X_arr)\n",
    "        y_tensor = torch.FloatTensor(y_arr).reshape(-1, 1)\n",
    "        self.model = MCDropoutNetwork(X_arr.shape[1])\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.BCELoss()\n",
    "        self.model.train()\n",
    "        for _ in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            out = self.model(X_tensor)\n",
    "            loss = criterion(out, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return self\n",
    "    def predict_uncertainty(self, X, n_samples=20):\n",
    "        self.model.train()\n",
    "        X_arr = X.values if hasattr(X, 'values') else X\n",
    "        X_tensor = torch.FloatTensor(X_arr)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                preds.append(self.model(X_tensor).numpy())\n",
    "        preds = np.array(preds)\n",
    "        return preds.mean(axis=0).flatten(), preds.std(axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training Experiment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Enter your HF Token here for TabPFN if needed\n",
    "# login(token=\"hf_...\") \n",
    "\n",
    "try:\n",
    "    DATA_PATH_PROC = 'heart_processed.csv'\n",
    "    DATA_PATH_BASE = 'cardio_base.csv'\n",
    "    X, y, concept_map = load_and_preprocess_data(DATA_PATH_PROC, base_path=DATA_PATH_BASE)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    print(\"XGBoost Test AUC:\", roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1]))\n",
    "    \n",
    "    print(\"Training Uncertainty Model...\")\n",
    "    unc_model = UncertaintyModel(epochs=50)\n",
    "    unc_model.fit(X_train, y_train)\n",
    "    means, stds = unc_model.predict_uncertainty(X_test.iloc[:20])\n",
    "    print(\"Uncertainty (Std Dev) for first 20 samples:\", stds)\n",
    "    \n",
    "    print(\"Training TabPFN (Subsampled for Demo)...\")\n",
    "    # Subsample for TabPFN cpu speed\n",
    "    X_train_sub = X_train.iloc[:1000]\n",
    "    y_train_sub = y_train.iloc[:1000]\n",
    "    tab = TabPFNClassifier(device='cpu')\n",
    "    tab.fit(X_train_sub, y_train_sub)\n",
    "    print(\"TabPFN Fitted.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find CSV files. Please upload them.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

with open(r'c:\Users\msgok\.gemini\antigravity\brain\6d214bd5-7b87-46d6-a2c2-8f70f8953c06\hackathon_submission.ipynb', 'w') as f:
    json.dump(notebook_structure, f, indent=2)

print("Notebook generated successfully.")
